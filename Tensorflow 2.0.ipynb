{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTALACIÓN TENSORFLOW 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install packaging\n",
    "!pip install tf-nightly-2.0-preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-dev20190204\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EAGER EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(3)\n",
    "# Impresión inmediata del valor de un objeto tf.Tensor\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinar tf.Tensor con Numpy y uso de tf.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(n):\n",
    "    end = tf.convert_to_tensor(n)\n",
    "    z = tf.constant(2)\n",
    "    # Uso de valores de objetos tf.Tensor en estructuras de control de flujo\n",
    "    for b in range(1, end):\n",
    "        c = tf.constant(b)\n",
    "        # La salida de tf.print se dirigirá a la salida stdout de C++ por lo que no se verá en este Jupyter Notebook\n",
    "        tf.print(\"El valor de c es: \", c, output_stream=sys.stdout)\n",
    "        print(\"El valor de c es: \" + str(c))\n",
    "        # Las operaciones de Numpy aceptan como argumentos objetos tf.Tensor\n",
    "        d = np.multiply(z, c)\n",
    "        print(\"El valor de d es: \" + str(d) + \" y su tipo es \" + str(d.dtype))\n",
    "        # Transformación de un objeto tf.Tensor en ndarray de Numpy\n",
    "        e = c.numpy()\n",
    "        print(\"El valor de e es: \" + str(e))\n",
    "        \n",
    "fun(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograph @tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emplear <b>@tf.function</b> para combinar los beneficios de los grafos con Eager Execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cualquier función llamada desde otra decorada con @tf.function también será ejecutada en modo de grafo\n",
    "def sum(x, y):\n",
    "    return tf.add(x, y)\n",
    "\n",
    "@tf.function\n",
    "def my_layer(x, y):\n",
    "    print(tf.test.is_gpu_available())\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        res = sum(x, y)\n",
    "    return res\n",
    "\n",
    "x = tf.constant(3)\n",
    "y = tf.constant(2)\n",
    "my_layer(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emplear <b>@tf.function</b> para transformar elementos de Python en sus correspondientes versiones de Tensorflow. \n",
    "* if --> tf.cond\n",
    "* while / for (Autograph soporta el uso de continue y break)--> tf.while_loop\n",
    "* for i in data --> data.reduce\n",
    "* print --> tf.print\n",
    "* assert --> tf.Assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recorrer desde 1 hasta i - 1 --> Si elem es divisible entre j imprimir elem\n",
    "@tf.function\n",
    "def my_f(i, j):\n",
    "    for elem in range(1, i):\n",
    "        if elem % j == 0:\n",
    "            print(elem)\n",
    "            \n",
    "my_f(10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimir el código generado por <b>Autograph</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tf.autograph.to_code(my_f.python_function, experimental_optional_features=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de gradientes con tf.GradientTape\n",
    "\n",
    "Tensorflow graba en un \"tape\" todas las operaciones ejecutadas dentro del contexto de un tf.GradientTape.Tensorflow usa ese \"tape\" para calcular los gradientes de las operaciones grabadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable([1.0])\n",
    "with tf.GradientTape() as tape:\n",
    "    l = w * w\n",
    "gradient = tape.gradient(l, w)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitaciones de Autograph\n",
    "<a src=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/LIMITATIONS.md\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/LIMITATIONS.md</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGAR DATOS CON TF.DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>tf.data.Dataset.from_tensor_slices</b> crea un objeto Dataset cuyos elementos son slices de los tensores de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[2, 3], [4, 5], [6, 7]])\n",
    "y = np.array([\"cat\", \"dog\", \"fox\"])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elem_x, elem_y in dataset:\n",
    "    print(elem_x.numpy(), elem_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de <b>CIFAR-10</b> está formado por 60000 imágenes de 32x32 píxeles. Hay 10 clases de imágenes y 6000 imágenes\n",
    "por cada clase repartidas en 50000 imágenes de entrenamiento y 10000 imágenes de test.<br>\n",
    "Las 10 clases son: <br>\n",
    "![title](cifar10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar10_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).shuffle(10000)\n",
    "    train_dataset = train_dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, \n",
    "                                                    tf.reshape(tf.one_hot(y, 10), (-1, 10))))\n",
    "    #train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "    train_dataset = train_dataset.repeat(1)\n",
    "    \n",
    "    valid_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).shuffle(10000)\n",
    "    valid_dataset = valid_dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, \n",
    "                                                    tf.reshape(tf.one_hot(y, 10), (-1, 10))))\n",
    "    valid_dataset = valid_dataset.repeat(1)\n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "train_dataset, valid_dataset = cifar10_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USAR CAPAS Y MODELOS DE KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras permite emplear diversas aproximaciones para construir la red: Sequential API, Functional API, Subclassing API.\n",
    "<br>Ahora vamos a ver un ejemplo de <b>Subclassing API</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(KModel, self).__init__(name='k_model')\n",
    "        self.num_classes = num_classes\n",
    "        # Definir las capas de la red\n",
    "        #self.reshape = tf.keras.layers.Reshape(target_reshape=(28, 28), input_shape=(28,28))\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, 5, padding='same', activation=tf.nn.relu, \n",
    "                                            #kernel_initializer=tf.compat.v1.variance_scaling_initializer, \n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(l=0.001))\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
    "        # variance_scaling: samples are drawn from a truncated normal distribution with a mean of zero and a \n",
    "        # standard deviation stddev = sqrt(scale / n) where n is: \n",
    "        # number of input units in the weight tensor\n",
    "        # regularization_l2 += tf.python.ops.math_ops.reduce_sum(self.l2 * math_ops.square(x))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 5, padding='same', activation=tf.nn.relu, \n",
    "                                            #kernel_initializer=tf.compat.v1.variance_scaling_initializer, \n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(l=0.001))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(750, activation=tf.nn.relu, \n",
    "                                         #kernel_initializer=tf.compat.v1.variance_scaling_initializer,\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(l=0.001))\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.maxpool(self.conv1(x))\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.maxpool(self.conv2(x))\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563==============================] - 310s 198ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8098a0290>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KModel(num_classes=10)\n",
    "# Keras accuracy K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./log/{}'.format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")))\n",
    "\n",
    "]\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=valid_dataset, validation_steps=3, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30==============================] - 1s 41ms/step - loss: 7.3224 - acc: 0.1156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.322403685251872, 0.115625]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate(data, labels, batch_size=32)\n",
    "model.evaluate(valid_dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = True\n",
    "for x , y in valid_dataset:\n",
    "    if i == True:\n",
    "        elem_x = x\n",
    "        elem_y = y\n",
    "        i = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(elem_x, batch_size=32)\n",
    "max_ind_res = tf.argmax(res, axis=1)\n",
    "print(max_ind_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 6 8 0 5 4 1 2 0 9 6 4 2 4 6 5 9 7 7 4 6 5 0 1 9 0 3 1 9 0 9 7], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.argmax(elem_y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.20445085e-01 4.74516681e-04 4.39676866e-02 3.49011533e-02\n",
      "  2.35347656e-07 1.66804617e-04 2.64197342e-06 4.20839683e-07\n",
      "  4.14171409e-05 5.65345246e-08]\n",
      " [7.94559717e-01 3.11323232e-03 1.79192171e-01 2.25958172e-02\n",
      "  1.34762843e-06 2.39591172e-04 5.11891994e-05 7.39940651e-06\n",
      "  2.37632601e-04 1.91255140e-06]\n",
      " [7.75377095e-01 7.15321079e-02 1.35324135e-01 1.69503745e-02\n",
      "  4.46334155e-07 1.39353069e-04 2.80247186e-05 2.04888984e-05\n",
      "  5.89387957e-04 3.84870909e-05]\n",
      " [9.94001448e-01 7.53943168e-04 4.97061620e-03 6.93867187e-05\n",
      "  2.38935627e-08 6.76246771e-07 1.89199852e-07 2.56242743e-08\n",
      "  2.02818424e-04 8.25951304e-07]\n",
      " [5.81852794e-01 1.76884903e-04 1.20578505e-01 2.93874979e-01\n",
      "  4.21841122e-07 3.48766893e-03 1.37631569e-05 2.29540433e-06\n",
      "  1.27146195e-05 7.60194041e-08]\n",
      " [7.41658807e-01 4.71866661e-04 2.26233169e-01 3.08853909e-02\n",
      "  1.68717133e-06 5.86691138e-04 3.00097054e-05 2.62865015e-05\n",
      "  1.04963648e-04 1.10801352e-06]\n",
      " [8.88136387e-01 1.75037177e-03 6.64514005e-02 4.31174710e-02\n",
      "  2.64879674e-07 3.36415251e-04 1.45403810e-05 3.20376898e-06\n",
      "  1.89114522e-04 7.33541242e-07]\n",
      " [4.99355495e-01 2.59876426e-04 4.07666266e-01 9.06860232e-02\n",
      "  1.16317949e-06 1.90846226e-03 8.06112075e-05 1.83719767e-05\n",
      "  2.35070365e-05 1.79444555e-07]\n",
      " [9.48070049e-01 1.83781493e-04 4.83244620e-02 3.28577962e-03\n",
      "  1.29156248e-07 2.66233674e-05 4.88653086e-06 6.77189405e-07\n",
      "  1.02995378e-04 6.45168086e-07]\n",
      " [9.25728261e-01 1.36405528e-02 5.04063852e-02 9.45490319e-03\n",
      "  3.15051750e-07 3.44612286e-04 9.94723905e-06 8.70218901e-06\n",
      "  3.49463458e-04 5.68423493e-05]\n",
      " [3.98166329e-01 2.11094785e-03 4.73595530e-01 1.23419039e-01\n",
      "  1.06390314e-06 2.44918722e-03 1.43914105e-04 5.65759947e-05\n",
      "  5.56046070e-05 1.85959163e-06]\n",
      " [5.99286437e-01 9.20712264e-05 3.36645156e-01 6.30847365e-02\n",
      "  1.49741948e-06 8.13454215e-04 3.83220031e-05 1.33451076e-05\n",
      "  2.48685865e-05 1.10010070e-07]\n",
      " [7.51836360e-01 2.57076499e-05 9.39300805e-02 1.50773779e-01\n",
      "  2.13291628e-07 3.41607747e-03 8.96572965e-06 3.66235781e-07\n",
      "  8.49718344e-06 3.99704305e-08]\n",
      " [6.86190307e-01 4.77256626e-03 1.06139421e-01 2.00663239e-01\n",
      "  9.18729370e-07 2.10628635e-03 2.87480198e-05 3.43727697e-05\n",
      "  6.30551294e-05 1.08850202e-06]\n",
      " [8.61567497e-01 7.85145722e-03 9.70561877e-02 3.28789353e-02\n",
      "  1.22501069e-06 4.28334140e-04 6.74084658e-05 9.78505432e-06\n",
      "  1.33720649e-04 5.43343549e-06]\n",
      " [9.03291523e-01 4.38374773e-05 7.80485868e-02 1.82196423e-02\n",
      "  1.07446901e-07 3.66442866e-04 2.18345963e-06 1.34268802e-07\n",
      "  2.75072471e-05 2.12370761e-08]\n",
      " [8.56085956e-01 9.68640447e-02 4.35181446e-02 2.17420538e-03\n",
      "  7.05394712e-07 1.57953618e-05 1.02906070e-05 1.29694627e-05\n",
      "  1.03519391e-03 2.82721681e-04]\n",
      " [4.76477057e-01 2.33490020e-04 3.98929358e-01 1.12187147e-01\n",
      "  5.97075177e-06 1.16107743e-02 3.95138981e-04 1.31013992e-04\n",
      "  2.58585587e-05 4.20242304e-06]\n",
      " [5.15079081e-01 1.86682749e-03 3.81338328e-01 1.00199528e-01\n",
      "  3.75156492e-06 1.08445343e-03 8.57100968e-05 1.43079422e-04\n",
      "  1.95273038e-04 3.89084471e-06]\n",
      " [8.61319602e-01 7.44632562e-05 1.20236196e-01 1.82019919e-02\n",
      "  1.68825537e-07 9.42764600e-05 8.46587045e-06 9.45704642e-07\n",
      "  6.38070123e-05 7.53227951e-08]\n",
      " [6.86716914e-01 3.34882131e-03 2.71488518e-01 3.77336778e-02\n",
      "  9.66161224e-07 4.99159680e-04 8.42674344e-05 3.83611914e-05\n",
      "  8.81854357e-05 1.18708681e-06]\n",
      " [5.81204653e-01 3.91570560e-04 3.84681314e-01 3.32023650e-02\n",
      "  2.44676983e-07 4.39395168e-04 1.98533817e-05 7.71412670e-06\n",
      "  5.26053445e-05 2.60668031e-07]\n",
      " [9.70364392e-01 4.68237093e-04 2.72506531e-02 1.81084289e-03\n",
      "  6.87343871e-08 8.87364149e-06 1.41886221e-06 4.87490183e-07\n",
      "  9.48165180e-05 1.84009082e-07]\n",
      " [6.32210732e-01 7.39882216e-02 2.68891662e-01 2.33862773e-02\n",
      "  3.78003938e-06 3.84853920e-04 1.98582769e-04 2.06509954e-04\n",
      "  4.73817403e-04 2.55595456e-04]\n",
      " [9.48573351e-01 1.14582153e-03 4.23484445e-02 7.66860554e-03\n",
      "  2.27356182e-07 3.31174087e-05 3.71784677e-06 3.54616350e-06\n",
      "  2.22122238e-04 9.78827870e-07]\n",
      " [9.59555507e-01 6.40478567e-04 3.81379165e-02 1.54848595e-03\n",
      "  9.89224489e-08 2.38131670e-05 2.49576624e-06 2.18886271e-07\n",
      "  9.07740468e-05 3.01339696e-07]\n",
      " [7.43806422e-01 3.31838392e-02 1.63438171e-01 5.89994565e-02\n",
      "  1.04158926e-06 7.45330108e-05 7.60820913e-05 2.28140307e-05\n",
      "  3.72533948e-04 2.50651283e-05]\n",
      " [8.12446833e-01 2.61758524e-03 1.51273191e-01 3.25392932e-02\n",
      "  3.41634063e-07 8.34066945e-04 1.24823237e-05 9.55136784e-05\n",
      "  1.72827451e-04 7.82926418e-06]\n",
      " [9.48229492e-01 5.19022765e-03 3.87570746e-02 7.65987672e-03\n",
      "  1.16831288e-07 7.77846944e-05 5.29354656e-06 2.39195765e-06\n",
      "  7.66375597e-05 1.11114014e-06]\n",
      " [9.99084353e-01 4.56046364e-05 7.83388910e-04 3.60925842e-05\n",
      "  3.54338336e-09 3.33641111e-07 4.80794498e-08 8.69221639e-10\n",
      "  5.00897149e-05 4.60868144e-08]\n",
      " [9.47624385e-01 3.78300878e-03 4.08324078e-02 7.48793734e-03\n",
      "  3.97602037e-07 6.74983021e-05 3.71765891e-05 6.19947627e-07\n",
      "  1.59144445e-04 7.37580967e-06]\n",
      " [9.16226804e-01 2.49025354e-04 6.98115975e-02 1.34231225e-02\n",
      "  2.56338581e-07 2.42041584e-04 8.23431492e-06 2.32495768e-06\n",
      "  3.63850741e-05 2.47505426e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]], shape=(32, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(elem_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Salvar los pesos en un fichero Checkpoint de Tensorflow \n",
    "model.save_weights('./kmodel_tf')\n",
    "# Restaurar el estado del modelo. Esto requiere que el modelo tenga la misma arquitectura que la red de los pesos\n",
    "model.load_weights('./kmodel_tf')\n",
    "\n",
    "# Salvar los pesos en formato HDF5 de Keras\n",
    "model.save_weights('./kmodel_k.h5', save_format='h5')\n",
    "# Restaurar el estado del modelo. Esto requiere que el modelo tenga la misma arquitectura que la red de los pesos\n",
    "model.load_weights('./kmodel_k.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar el modelo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SavedModel es un formato serializado que contendrá las variables, el grafo y los metadatos del grafo.\n",
    "# Permite que herramientas de alto nivel como tensorflow/serving, la herramienta de línea de comandos saved_model\n",
    "model_path = \"/home/turtlebot/full_model\"\n",
    "tf.saved_model.save(model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
